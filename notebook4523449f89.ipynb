{"metadata":{"colab":{"collapsed_sections":["RRee1h1TPAGp"],"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8871727,"sourceType":"datasetVersion","datasetId":5339425},{"sourceId":9100567,"sourceType":"datasetVersion","datasetId":5492083},{"sourceId":9101433,"sourceType":"datasetVersion","datasetId":5492767},{"sourceId":9101441,"sourceType":"datasetVersion","datasetId":5492774}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"2ZCAG0I3vt7j"}},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport soundfile\nimport IPython\nimport shutil","metadata":{"id":"zDK8CLo0u5vD","execution":{"iopub.status.busy":"2024-08-04T07:47:40.083995Z","iopub.execute_input":"2024-08-04T07:47:40.084825Z","iopub.status.idle":"2024-08-04T07:47:40.174106Z","shell.execute_reply.started":"2024-08-04T07:47:40.084792Z","shell.execute_reply":"2024-08-04T07:47:40.173405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"DaF6FlrUwXYj"}},{"cell_type":"code","source":"def audio_to_audio_frame_stack(sound_data, frame_length, hop_length_frame):\n    \"\"\"This function take an audio and split into several frame\n       in a numpy matrix of size (nb_frame,frame_length)\"\"\"\n\n    sequence_sample_length = sound_data.shape[0]\n    # Creating several audio frames using sliding windows\n    sound_data_list = [sound_data[start:start + frame_length] for start in range(\n    0, sequence_sample_length - frame_length + 1, hop_length_frame)]  # get sliding windows\n    # Combining all the frames to single matrix\n    sound_data_array = np.vstack(sound_data_list)\n    return sound_data_array","metadata":{"id":"ReTajSWLc9aT","execution":{"iopub.status.busy":"2024-08-04T07:51:53.994245Z","iopub.execute_input":"2024-08-04T07:51:53.994979Z","iopub.status.idle":"2024-08-04T07:51:54.000512Z","shell.execute_reply.started":"2024-08-04T07:51:53.994948Z","shell.execute_reply":"2024-08-04T07:51:53.999648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Required variables for Audio\nnoisy_audio_dir=\"/kaggle/input/letsdoit/MIXED/content/MIXED/\"\nvoice_dir=\"/kaggle/input/letsdoit/ORIGINAL/content/ORIGINAL/\"\npath_save_spectrogram=\"/content/spectogram/\"\nsample_rate=8000\nmin_duration=1.0  \nframe_length=8064\nhop_length_frame=8064\nhop_length_frame_noise=5000\nnb_samples=500\nn_fft=255\nhop_length_fft=63\ndim_square_spec = int(n_fft / 2) + 1","metadata":{"id":"wvI7udCs23sJ","execution":{"iopub.status.busy":"2024-08-04T07:51:56.209518Z","iopub.execute_input":"2024-08-04T07:51:56.210128Z","iopub.status.idle":"2024-08-04T07:51:56.215303Z","shell.execute_reply.started":"2024-08-04T07:51:56.210086Z","shell.execute_reply":"2024-08-04T07:51:56.214383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean Audio files\nclean_audio_files = os.listdir(voice_dir)\ni=np.random.randint(1000)\n# Selecting a random audio from clean speech\nclean_random_audio = f\"original_\"+str(i).zfill(4)+\".wav\"\n# Load Audio\ny,sr = librosa.load(os.path.join(voice_dir,clean_random_audio),sr=sample_rate)\n# Converting to Audio to numpy matrix\nclean = audio_to_audio_frame_stack(y,frame_length,hop_length_frame)\nprint(\"Clean Audio: {}\".format(clean_random_audio))\nprint(\"Shape:{}\".format(clean.shape))","metadata":{"id":"eeXVCryW1SiP","outputId":"01b517b1-6840-453b-f2ef-9e3c8805dc99","execution":{"iopub.status.busy":"2024-08-04T07:52:01.63596Z","iopub.execute_input":"2024-08-04T07:52:01.636318Z","iopub.status.idle":"2024-08-04T07:52:17.376805Z","shell.execute_reply.started":"2024-08-04T07:52:01.636291Z","shell.execute_reply":"2024-08-04T07:52:17.375843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Noisy Audio files\nnoisy_audio_files = os.listdir(noisy_audio_dir)\n# Selecting a random noisy audio from noisy audio data\nnoisy_random_audio = f\"combined_\"+str(i).zfill(4)+\".wav\"\n# Load Audio\ny,sr = librosa.load(os.path.join(noisy_audio_dir,noisy_random_audio),sr=sample_rate)\n# Converting the Audio to numpy matrix\nnoise = audio_to_audio_frame_stack(y,frame_length,hop_length_frame)\nprint(\"Noise Audio: {}\".format(noisy_random_audio))\nprint(\"Shape:{}\".format(noise.shape))","metadata":{"id":"ru85SM_s6IPn","outputId":"48c61f4b-5540-46f2-981d-02a9b86d079d","execution":{"iopub.status.busy":"2024-08-04T07:52:21.517284Z","iopub.execute_input":"2024-08-04T07:52:21.517946Z","iopub.status.idle":"2024-08-04T07:52:21.900108Z","shell.execute_reply.started":"2024-08-04T07:52:21.517896Z","shell.execute_reply":"2024-08-04T07:52:21.899236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For example, Let's implement this for our random noise and clean speech","metadata":{"id":"K93odM037O8A"}},{"cell_type":"code","source":"clean = np.vstack(clean)\nnoise = np.vstack(noise)","metadata":{"id":"dxWDrTWv58sJ","execution":{"iopub.status.busy":"2024-08-04T07:52:28.077501Z","iopub.execute_input":"2024-08-04T07:52:28.077857Z","iopub.status.idle":"2024-08-04T07:52:28.082727Z","shell.execute_reply.started":"2024-08-04T07:52:28.077827Z","shell.execute_reply":"2024-08-04T07:52:28.081907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clean)\nprint(noise)","metadata":{"id":"GE1RWyU37fjM","outputId":"1135e15b-292a-4fef-dd0b-fe564f5af9bd","execution":{"iopub.status.busy":"2024-08-04T07:52:30.011955Z","iopub.execute_input":"2024-08-04T07:52:30.012791Z","iopub.status.idle":"2024-08-04T07:52:30.018203Z","shell.execute_reply.started":"2024-08-04T07:52:30.01276Z","shell.execute_reply":"2024-08-04T07:52:30.017332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prod_voice=clean\nprod_noisy_voice=noise","metadata":{"id":"GgP_4kzXuoLk","outputId":"3cdedb46-0f2d-4f0b-faec-c6ee637c3f0b","execution":{"iopub.status.busy":"2024-08-04T07:52:40.635923Z","iopub.execute_input":"2024-08-04T07:52:40.636293Z","iopub.status.idle":"2024-08-04T07:52:40.64016Z","shell.execute_reply.started":"2024-08-04T07:52:40.636265Z","shell.execute_reply":"2024-08-04T07:52:40.639171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples_clean = []\nsamples_noisy_clean = []\nfor x in clean:\n  samples_clean.extend(x)\n\nfor x in noise:\n  samples_noisy_clean.extend(x)","metadata":{"id":"yPh7ITSzAM2r","execution":{"iopub.status.busy":"2024-08-04T06:54:07.903898Z","iopub.execute_input":"2024-08-04T06:54:07.904809Z","iopub.status.idle":"2024-08-04T06:54:07.91307Z","shell.execute_reply.started":"2024-08-04T06:54:07.904774Z","shell.execute_reply":"2024-08-04T06:54:07.911927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After combining all samples to 1 (10*8064)\nlen(samples_clean)","metadata":{"id":"7qncxghYB2Zb","outputId":"cdfc774b-22c6-493c-da77-4128c77f83f4","execution":{"iopub.status.busy":"2024-08-04T06:54:10.631367Z","iopub.execute_input":"2024-08-04T06:54:10.632581Z","iopub.status.idle":"2024-08-04T06:54:10.639149Z","shell.execute_reply.started":"2024-08-04T06:54:10.632529Z","shell.execute_reply":"2024-08-04T06:54:10.63828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(30,10))\nplt.subplot(211)\nplt.title(\"Clean Speech\")\nplt.plot(samples_clean)\n\nplt.subplot(212)\nplt.title(\"Noisy Speech\")\nplt.plot(samples_noisy_clean)\n\nplt.show()","metadata":{"id":"4JE5FWMl8DdL","outputId":"ef0c81d0-d558-4428-ad83-e85217bcedc0","execution":{"iopub.status.busy":"2024-08-04T06:54:13.446399Z","iopub.execute_input":"2024-08-04T06:54:13.447141Z","iopub.status.idle":"2024-08-04T06:54:14.087237Z","shell.execute_reply.started":"2024-08-04T06:54:13.447109Z","shell.execute_reply":"2024-08-04T06:54:14.086234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving and playing clean voice\nimport soundfile as sf\nclean_nb_samples = clean.shape[0]\n#Save all frames in one file\nclean_long = clean.reshape(1, 3 * frame_length)*109\n# librosa.output.write_wav(dir_save_prediction + audio_output_prediction, denoise_long[0, :], 1000)\nsf.write(\"cleanAUDIO.wav\", clean_long[0,:], 8000, 'PCM_24')","metadata":{"id":"GhMirTZcuak4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Audio\nAudio(\"cleanAUDIO.wav\")","metadata":{"id":"jmxptcORybyB","outputId":"a60b1c3c-3607-402b-af80-8a8fb0910773","execution":{"iopub.status.busy":"2024-08-03T23:10:22.818018Z","iopub.execute_input":"2024-08-03T23:10:22.818402Z","iopub.status.idle":"2024-08-03T23:10:22.829642Z","shell.execute_reply.started":"2024-08-03T23:10:22.818372Z","shell.execute_reply":"2024-08-03T23:10:22.828627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving and playing noisy voice\nnoise_nb_samples = noise.shape[0]\n#Save all frames in one file\nnoise_long = noise.reshape(1, 3 * frame_length)*10\n# librosa.output.write_wav(dir_save_prediction + audio_output_prediction, denoise_long[0, :], 1000)\nsf.write(\"noisyAUDIO.wav\", noise_long[0,:], 8000, 'PCM_24')","metadata":{"id":"KSfOaSs3wq0N","execution":{"iopub.status.busy":"2024-08-03T23:10:32.180614Z","iopub.execute_input":"2024-08-03T23:10:32.180946Z","iopub.status.idle":"2024-08-03T23:10:32.191635Z","shell.execute_reply.started":"2024-08-03T23:10:32.180922Z","shell.execute_reply":"2024-08-03T23:10:32.190558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Audio\nAudio('noisyAUDIO.wav')","metadata":{"id":"fnyUdL2DykIj","outputId":"33392616-18b7-433a-eca9-42b4f2290aa4","execution":{"iopub.status.busy":"2024-08-03T23:10:43.951789Z","iopub.execute_input":"2024-08-03T23:10:43.952633Z","iopub.status.idle":"2024-08-03T23:10:43.959676Z","shell.execute_reply.started":"2024-08-03T23:10:43.9526Z","shell.execute_reply":"2024-08-03T23:10:43.958825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, audio):\n    \"\"\"This function takes an audio and convert into spectrogram,\n       it returns the magnitude in dB and the phase\"\"\"\n\n    \n    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n\n    stftaudio_magnitude_db = librosa.amplitude_to_db(\n        stftaudio_magnitude, ref=np.max)\n\n    return stftaudio_magnitude_db, stftaudio_phase","metadata":{"id":"tUMXmHMkkfDk","execution":{"iopub.status.busy":"2024-08-03T23:11:02.104541Z","iopub.execute_input":"2024-08-03T23:11:02.105149Z","iopub.status.idle":"2024-08-03T23:11:02.110568Z","shell.execute_reply.started":"2024-08-03T23:11:02.105104Z","shell.execute_reply":"2024-08-03T23:11:02.109653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def numpy_audio_to_matrix_spectrogram(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n    \"\"\"This function takes as input a numpy audi of size (nb_frame,frame_length), and return\n    a numpy containing the matrix spectrogram for amplitude in dB and phase. It will have the size\n    (nb_frame,dim_square_spec,dim_square_spec)\"\"\"\n\n    # we extract the magnitude vectors from the 256-point STFT vectors and \n    # take the first 129-point by removing the symmetric half.\n\n    nb_audio = numpy_audio.shape[0]\n    # dim_square_spec = 256/2\n    m_mag_db = np.zeros((nb_audio, dim_square_spec, dim_square_spec))\n    m_phase = np.zeros((nb_audio, dim_square_spec, dim_square_spec), dtype=complex)\n\n    for i in range(nb_audio):\n        m_mag_db[i, :, :], m_phase[i, :, :] = audio_to_magnitude_db_and_phase(\n            n_fft, hop_length_fft, numpy_audio[i])\n#     print(m_phase)\n#     print(m_mag_db)\n    return m_mag_db, m_phase","metadata":{"id":"IE5XOVzYjAxc","execution":{"iopub.status.busy":"2024-08-03T23:11:11.9011Z","iopub.execute_input":"2024-08-03T23:11:11.90173Z","iopub.status.idle":"2024-08-03T23:11:11.908497Z","shell.execute_reply.started":"2024-08-03T23:11:11.901697Z","shell.execute_reply":"2024-08-03T23:11:11.907435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame, min_duration):\n    \"\"\"This function take audio files of a directory and merge them\n    in a numpy matrix of size (nb_frame,frame_length) for a sliding window of size hop_length_frame\"\"\"\n\n    list_sound_array = []\n\n    count = 0\n    for file in list_audio_files:\n    # open the audio file\n      try:\n        y, sr = librosa.load(os.path.join(audio_dir, file), sr=sample_rate)\n        # Getting duration of audio file\n        total_duration = librosa.get_duration(y=y, sr=sr)\n      except ZeroDivisionError:\n        count += 1\n\n        # Check if the duration is atleast the minimum duration\n      if (total_duration >= min_duration):\n          list_sound_array.append(audio_to_audio_frame_stack(\n              y, frame_length, hop_length_frame))\n      else:\n          print(\n              f\"The following file {os.path.join(audio_dir,file)} is below the min duration\")\n    print(count)\n    return np.vstack(list_sound_array)\n","metadata":{"id":"kIJ3Z0h2ct1L","execution":{"iopub.status.busy":"2024-08-04T07:49:41.295356Z","iopub.execute_input":"2024-08-04T07:49:41.295945Z","iopub.status.idle":"2024-08-04T07:49:41.302908Z","shell.execute_reply.started":"2024-08-04T07:49:41.295914Z","shell.execute_reply":"2024-08-04T07:49:41.302016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Prepare\ndef create_data(noise_dir, voice_dir,path_save_spectrogram, sample_rate,\nmin_duration, frame_length, hop_length_frame, hop_length_frame_noise, nb_samples, n_fft, hop_length_fft):\n\n\n    list_noise_files = os.listdir(noise_dir)\n    list_voice_files = os.listdir(voice_dir)\n\n    def remove_ds_store(lst):\n        \"\"\"remove mac specific file if present\"\"\"\n        if '.DS_Store' in lst:\n            lst.remove('.DS_Store')\n\n        return lst\n\n    list_noise_files = remove_ds_store(list_noise_files)\n    list_voice_files = remove_ds_store(list_voice_files)\n\n    nb_voice_files = len(list_voice_files)\n    nb_noise_files = len(list_noise_files)\n\n\n    # Extracting noise and voice from folder and convert to numpy\n    noise = audio_files_to_numpy(noise_dir, list_noise_files, sample_rate,\n                                     frame_length, hop_length_frame_noise, min_duration)\n\n    voice = audio_files_to_numpy(voice_dir, list_voice_files,\n                                     sample_rate, frame_length, hop_length_frame, min_duration)\n\n    # Blend some clean voices with random selected noises (and a random level of noise)\n#     prod_voice, prod_noise, prod_noisy_voice = blend_noise_randomly(\n#             voice, noise, nb_samples, frame_length)\n\n\n    # Squared spectrogram dimensions\n    dim_square_spec = int(n_fft / 2) + 1\n\n    # Create Amplitude and phase of the sounds\n    m_amp_db_voice,  m_pha_voice = numpy_audio_to_matrix_spectrogram(\n            voice, dim_square_spec, n_fft, hop_length_fft)\n    m_amp_db_noise,  m_pha_noise = numpy_audio_to_matrix_spectrogram(\n            noise, dim_square_spec, n_fft, hop_length_fft)\n#     m_amp_db_noisy_voice,  m_pha_noisy_voice = numpy_audio_to_matrix_spectrogram(\n#             prod_noisy_voice, dim_square_spec, n_fft, hop_length_fft)\n\n    np.save(path_save_spectrogram + 'clean_audio_amp_db', m_amp_db_voice)\n    np.save(path_save_spectrogram + 'noisy_audio_amp_db', m_amp_db_noise)                 \n","metadata":{"id":"t9PaV74Nltqc","execution":{"iopub.status.busy":"2024-08-03T23:11:25.822473Z","iopub.execute_input":"2024-08-03T23:11:25.823302Z","iopub.status.idle":"2024-08-03T23:11:25.832671Z","shell.execute_reply.started":"2024-08-03T23:11:25.823265Z","shell.execute_reply":"2024-08-03T23:11:25.831547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating folder save the audio spectograms\n!mkdir spectogram","metadata":{"id":"ZzzOKhIanhOt","execution":{"iopub.status.busy":"2024-08-03T23:11:33.078402Z","iopub.execute_input":"2024-08-03T23:11:33.079114Z","iopub.status.idle":"2024-08-03T23:11:34.128952Z","shell.execute_reply.started":"2024-08-03T23:11:33.079074Z","shell.execute_reply":"2024-08-03T23:11:34.127573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noise_dir=\"/kaggle/input/letsdoit/MIXED/content/MIXED/\"\nvoice_dir=\"/kaggle/input/letsdoit/ORIGINAL/content/ORIGINAL/\"\npath_save_spectrogram=\"/kaggle/working/\"\nsample_rate=8000\nmin_duration=1.0  \nframe_length=8064\nhop_length_frame=8064\nhop_length_frame_noise=8064\nnb_samples=1000\nn_fft=255\nhop_length_fft=63","metadata":{"id":"m_YTIhDomrIU","execution":{"iopub.status.busy":"2024-08-03T23:11:41.243365Z","iopub.execute_input":"2024-08-03T23:11:41.243762Z","iopub.status.idle":"2024-08-03T23:11:41.249408Z","shell.execute_reply.started":"2024-08-03T23:11:41.243729Z","shell.execute_reply":"2024-08-03T23:11:41.248529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_data(noise_dir=voice_dir,voice_dir=noise_dir,\n            path_save_spectrogram=path_save_spectrogram,\n            sample_rate=sample_rate,min_duration=min_duration,frame_length=frame_length,hop_length_frame=hop_length_frame,hop_length_frame_noise=hop_length_frame_noise,nb_samples=nb_samples,n_fft=n_fft,hop_length_fft=hop_length_fft)","metadata":{"id":"WQA2cbYcnOcc","execution":{"iopub.status.busy":"2024-08-03T23:11:46.278385Z","iopub.execute_input":"2024-08-03T23:11:46.278715Z","iopub.status.idle":"2024-08-03T23:12:14.365466Z","shell.execute_reply.started":"2024-08-03T23:11:46.278691Z","shell.execute_reply":"2024-08-03T23:12:14.364427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_audio_db = np.load('/kaggle/working/clean_audio_amp_db.npy')\nprint(np.shape(clean_audio_db))","metadata":{"id":"ohNGRc0FB0j9","outputId":"d23887c7-9afa-41b7-cc01-888097853931","execution":{"iopub.status.busy":"2024-08-03T23:13:12.782062Z","iopub.execute_input":"2024-08-03T23:13:12.782712Z","iopub.status.idle":"2024-08-03T23:13:12.90793Z","shell.execute_reply.started":"2024-08-03T23:13:12.78268Z","shell.execute_reply":"2024-08-03T23:13:12.906995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"noisy_audio_db = np.load('/kaggle/working/noisy_audio_amp_db.npy')\nprint(np.shape(noisy_audio_db))","metadata":{"execution":{"iopub.status.busy":"2024-08-03T23:13:15.608192Z","iopub.execute_input":"2024-08-03T23:13:15.608548Z","iopub.status.idle":"2024-08-03T23:13:15.735264Z","shell.execute_reply.started":"2024-08-03T23:13:15.608524Z","shell.execute_reply":"2024-08-03T23:13:15.734285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D,Conv2DTranspose, LeakyReLU, MaxPooling2D, Dropout, concatenate, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend\nimport tensorflow as tf\n# print(tf.__version__)\n\n#Unet network\ndef unet(input_size = (128,128,1)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2DTranspose(32,2,strides=(2,2),padding='same')(drop5)\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2DTranspose(64,2,strides=(2,2),padding='same')(conv6)\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2DTranspose(32,2,strides=(2,2),padding='same')(conv7)\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2DTranspose(16,2,strides=(2,2),padding='same')(conv8)\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'tanh')(conv9)\n\n    model = Model(inputs,conv10)\n\n    model.compile(optimizer = Adam(learning_rate = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n\n#     model.summary()\n    return model\n    ","metadata":{"id":"BUn4r-Q5wfnj","execution":{"iopub.status.busy":"2024-08-03T11:46:24.551525Z","iopub.execute_input":"2024-08-03T11:46:24.552159Z","iopub.status.idle":"2024-08-03T11:46:35.604344Z","shell.execute_reply.started":"2024-08-03T11:46:24.552124Z","shell.execute_reply":"2024-08-03T11:46:35.603375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input\nnoisy_audio = noisy_audio[:,:,:]\nnoisy_audio = noisy_audio.reshape(noisy_audio.shape[0],noisy_audio.shape[1],noisy_audio.shape[2],1)\n# Output\nclean_audio = clean_audio[:,:,:]\nclean_audio = clean_audio.reshape(clean_audio.shape[0],clean_audio.shape[1],clean_audio.shape[2],1)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:46:37.792401Z","iopub.execute_input":"2024-08-03T11:46:37.793571Z","iopub.status.idle":"2024-08-03T11:46:37.80232Z","shell.execute_reply.started":"2024-08-03T11:46:37.793527Z","shell.execute_reply":"2024-08-03T11:46:37.800682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(noisy_audio.shape)\nprint(clean_audio.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:46:41.587698Z","iopub.execute_input":"2024-08-03T11:46:41.588501Z","iopub.status.idle":"2024-08-03T11:46:41.592818Z","shell.execute_reply.started":"2024-08-03T11:46:41.588469Z","shell.execute_reply":"2024-08-03T11:46:41.591843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(noisy_audio[3])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:46:45.078307Z","iopub.execute_input":"2024-08-03T11:46:45.078649Z","iopub.status.idle":"2024-08-03T11:46:45.08513Z","shell.execute_reply.started":"2024-08-03T11:46:45.078622Z","shell.execute_reply":"2024-08-03T11:46:45.083937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scaled_in(matrix_spec):\n    \"global scaling apply to noisy voice spectrograms (scale between -1 and 1)\"\n    matrix_spec = (matrix_spec + 46)/82\n    return matrix_spec\ndef scaled_ou(matrix_spec):\n    \"global scaling apply to noise models spectrograms (scale between -1 and 1)\"\n    matrix_spec = (matrix_spec -6 )/82\n    return matrix_spec","metadata":{"id":"0B7nYrZp1YDt","execution":{"iopub.status.busy":"2024-08-04T07:49:32.030032Z","iopub.execute_input":"2024-08-04T07:49:32.031228Z","iopub.status.idle":"2024-08-04T07:49:32.036205Z","shell.execute_reply.started":"2024-08-04T07:49:32.031183Z","shell.execute_reply":"2024-08-04T07:49:32.035224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnoise = noisy_audio-clean_audio","metadata":{"id":"lqXQQPn0W4FR","execution":{"iopub.status.busy":"2024-08-03T11:46:58.25595Z","iopub.execute_input":"2024-08-03T11:46:58.256602Z","iopub.status.idle":"2024-08-03T11:46:58.408065Z","shell.execute_reply.started":"2024-08-03T11:46:58.256571Z","shell.execute_reply":"2024-08-03T11:46:58.407271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_audio=scaled_ou(clean_audio)\nnoisy_audio=scaled_in(noisy_audio)","metadata":{"id":"zs24fb_jXVvB","outputId":"1255170a-a21a-4ca5-f460-4b5ba65b639a","execution":{"iopub.status.busy":"2024-08-03T11:47:54.321125Z","iopub.execute_input":"2024-08-03T11:47:54.321495Z","iopub.status.idle":"2024-08-03T11:47:54.632476Z","shell.execute_reply.started":"2024-08-03T11:47:54.321467Z","shell.execute_reply":"2024-08-03T11:47:54.631595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clean_audio[0])\nprint(noisy_audio[30])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T11:47:58.083492Z","iopub.execute_input":"2024-08-03T11:47:58.083846Z","iopub.status.idle":"2024-08-03T11:47:58.090563Z","shell.execute_reply.started":"2024-08-03T11:47:58.083819Z","shell.execute_reply":"2024-08-03T11:47:58.089629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input\nnoisy_voice = noisy_audio[:,:,:]\nnoisy_voice = noisy_voice.reshape(noisy_voice.shape[0],noisy_voice.shape[1],noisy_voice.shape[2],1)\n# Output\nclean_voice = clean_audio[:,:,:]\nclean_voice = clean_voice.reshape(clean_voice.shape[0],clean_voice.shape[1],clean_voice.shape[2],1)","metadata":{"id":"XW4zv6VhX2dZ","execution":{"iopub.status.busy":"2024-08-03T11:49:28.896259Z","iopub.execute_input":"2024-08-03T11:49:28.896896Z","iopub.status.idle":"2024-08-03T11:49:28.902307Z","shell.execute_reply.started":"2024-08-03T11:49:28.896863Z","shell.execute_reply":"2024-08-03T11:49:28.901273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shapes after reshaping\n\nprint(noisy_audio.shape)\nprint(noise.shape)\nprint(noisy_audio[3])","metadata":{"id":"eAqkoB6NYP4q","outputId":"5eb414d0-180b-4d3a-cefe-1f42d68cd819","execution":{"iopub.status.busy":"2024-08-03T11:48:26.372141Z","iopub.execute_input":"2024-08-03T11:48:26.372924Z","iopub.status.idle":"2024-08-03T11:48:26.378575Z","shell.execute_reply.started":"2024-08-03T11:48:26.372889Z","shell.execute_reply":"2024-08-03T11:48:26.377613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas\nfrom tensorflow.keras.models import model_from_json\nimport numpy as np\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\ndef training_unet(path_save_spectrogram, weights_path, epochs, batch_size):\n    \"\"\" This function will read noisy voice and clean voice spectrograms created by data_creation mode,\n    and train a Unet model on this dataset for epochs and batch_size specified. It saves best models to disk regularly.\n    \"\"\"\n    \n\n    X_train, X_test, y_train, y_test = train_test_split(noisy_audio, clean_audio, test_size=0.10, random_state=42)\n\n    generator_nn=unet()\n\n#     Save best models to disk during training\n    checkpoint = ModelCheckpoint(weights_path+'/model_unet_best.weights.h5',save_weights_only=True, verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n\n#     generator_nn.summary()\n\n    #Training\n    history = generator_nn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True,  verbose=1, validation_data=(X_test, y_test))\n    model_in_json = generator_nn.to_json()\n\n#     Saving Model\n    with open(weights_path+'model_unet.json','w') as json_file:\n      json_file.write(model_in_json)\n\n    #Plot training and validation loss (log scale)\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(loss) + 1)\n\n    plt.plot(epochs, loss, label='Training loss')\n    plt.plot(epochs, val_loss, label='Validation loss')\n    plt.yscale('log')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.show()","metadata":{"id":"qaCMvQ-OoT99","execution":{"iopub.status.busy":"2024-08-04T06:52:35.983139Z","iopub.execute_input":"2024-08-04T06:52:35.983531Z","iopub.status.idle":"2024-08-04T06:52:36.709148Z","shell.execute_reply.started":"2024-08-04T06:52:35.983498Z","shell.execute_reply":"2024-08-04T06:52:36.708128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir weights","metadata":{"id":"UXfC6QEH0cmI","execution":{"iopub.status.busy":"2024-07-08T12:28:49.851566Z","iopub.execute_input":"2024-07-08T12:28:49.852681Z","iopub.status.idle":"2024-07-08T12:28:50.860319Z","shell.execute_reply.started":"2024-07-08T12:28:49.852644Z","shell.execute_reply":"2024-07-08T12:28:50.859312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nfrom tensorflow import keras\nimport segmentation_models as sm\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T06:52:48.539991Z","iopub.execute_input":"2024-08-04T06:52:48.54065Z","iopub.status.idle":"2024-08-04T06:52:48.615234Z","shell.execute_reply.started":"2024-08-04T06:52:48.540617Z","shell.execute_reply":"2024-08-04T06:52:48.614092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_2(path_save_spectrogram, './weights', epochs= 20,batch_size=10)","metadata":{"id":"D46HSOkaYFOA","outputId":"c98d67d8-3e43-4df7-d62a-d7540c998291","execution":{"iopub.status.busy":"2024-08-03T23:22:50.518079Z","iopub.execute_input":"2024-08-03T23:22:50.518936Z","iopub.status.idle":"2024-08-03T23:36:55.822516Z","shell.execute_reply.started":"2024-08-03T23:22:50.518904Z","shell.execute_reply":"2024-08-03T23:36:55.821539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Helper Functions\ndef magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, stftaudio_magnitude_db, stftaudio_phase):\n    \"\"\"This functions reverts a spectrogram to an audio\"\"\"\n\n    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n\n    # taking magnitude and phase of audio\n    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n    audio_reconstruct = librosa.core.istft(audio_reverse_stft, hop_length=hop_length_fft, length=frame_length)\n\n    return audio_reconstruct\n\n\ndef matrix_spectrogram_to_numpy_audio(m_mag_db, m_phase, frame_length, hop_length_fft)  :\n    \"\"\"This functions reverts the matrix spectrograms to numpy audio\"\"\"\n\n    list_audio = []\n\n    nb_spec = m_mag_db.shape[0]\n\n    for i in range(nb_spec):\n\n        audio_reconstruct = magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, m_mag_db[i], m_phase[i])\n        list_audio.append(audio_reconstruct)\n\n    return np.vstack(list_audio)\n\ndef inv_scaled_ou(matrix_spec):\n    \"inverse global scaling apply to noise models spectrograms\"\n    matrix_spec = matrix_spec * 82 + 6\n    return matrix_spec\n","metadata":{"id":"8Hy0MMA1IE6A","execution":{"iopub.status.busy":"2024-08-04T07:53:45.403736Z","iopub.execute_input":"2024-08-04T07:53:45.404446Z","iopub.status.idle":"2024-08-04T07:53:45.411973Z","shell.execute_reply.started":"2024-08-04T07:53:45.404411Z","shell.execute_reply":"2024-08-04T07:53:45.411024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import librosa\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import model_from_json\nimport soundfile as sf\n\ndef prediction(weights_path, audio_dir_prediction, dir_save_prediction, audio_input_prediction,\naudio_output_prediction):\n    loaded_model = model\n    # load weights into new model\n    \n    print(\"Loaded model from disk\")\n\n    # Extracting noise and voice from folder and convert to numpy\n    audio = audio_files_to_numpy(audio_dir_prediction, audio_input_prediction, sample_rate,\n                                 frame_length, hop_length_frame, min_duration)\n\n    dim_square_spec = int(n_fft / 2) + 1\n    print(dim_square_spec)\n\n    # Create Amplitude and phase of the sounds\n    m_amp_db_audio,  m_pha_audio = numpy_audio_to_matrix_spectrogram(\n        audio, dim_square_spec, n_fft, hop_length_fft)\n\n    #global scaling to have distribution -1/1\n    X_in = scaled_in(m_amp_db_audio)\n    #Reshape for prediction\n    X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n    #Prediction using loaded network\n    X_pred = loaded_model.predict(X_in)\n    #Rescale back the noise model\n    inv_sca_X_pred = inv_scaled_ou(X_pred)\n    #Remove noise model from noisy speech\n    X_denoise = m_amp_db_audio - inv_sca_X_pred[:,:,:,0]\n    #Reconstruct audio from denoised spectrogram and phase\n    print(X_denoise.shape)\n    print(m_pha_audio.shape)\n    print(frame_length)\n    print(hop_length_fft)\n    audio_denoise_recons = matrix_spectrogram_to_numpy_audio(X_denoise, m_pha_audio, frame_length, hop_length_fft)\n    #Number of frames\n    nb_samples = audio_denoise_recons.shape[0]\n    #Save all frames in one file\n    denoise_long = audio_denoise_recons.reshape(1, nb_samples * frame_length)*10\n    # librosa.output.write_wav(dir_save_prediction + audio_output_prediction, denoise_long[0, :], 1000)\n    sf.write(dir_save_prediction + audio_output_prediction, denoise_long[0, :], 8000, 'PCM_24')\n    # wavfile.write(dir_save_prediction + audio_output_prediction, 1000, denoise_long[0,:])","metadata":{"id":"ovavIwHlZta5","execution":{"iopub.status.busy":"2024-08-04T06:06:48.807905Z","iopub.execute_input":"2024-08-04T06:06:48.809122Z","iopub.status.idle":"2024-08-04T06:06:48.819557Z","shell.execute_reply.started":"2024-08-04T06:06:48.809086Z","shell.execute_reply":"2024-08-04T06:06:48.818564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Predictions","metadata":{"id":"8AYmDOLGU3pr"}},{"cell_type":"code","source":"# Sample Noisy audio for Prediction\n!gdown 1dNs_LqsPFY3R4lMBMfejHFJAn4zfsbtK\n!gdown 1MsVGoIFR7350Hdeh3sJdqSzMsKuVoD-0","metadata":{"id":"vGdpaUSlJRPZ","outputId":"36691679-7a3e-431e-fff9-c002f7325cd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install pydub","metadata":{"id":"JQVhtR6nRIXf","outputId":"cddaf7dd-bda1-42d1-9996-d695532fa345","execution":{"iopub.status.busy":"2024-07-05T19:04:25.301081Z","iopub.execute_input":"2024-07-05T19:04:25.301485Z","iopub.status.idle":"2024-07-05T19:04:41.847904Z","shell.execute_reply.started":"2024-07-05T19:04:25.301456Z","shell.execute_reply":"2024-07-05T19:04:41.846414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment","metadata":{"id":"lHq-T2OrRLD6","execution":{"iopub.status.busy":"2024-07-05T19:04:41.85075Z","iopub.execute_input":"2024-07-05T19:04:41.851132Z","iopub.status.idle":"2024-07-05T19:04:41.872301Z","shell.execute_reply.started":"2024-07-05T19:04:41.851099Z","shell.execute_reply":"2024-07-05T19:04:41.871182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def amplify(path):\n  song = AudioSegment.from_wav(song)\n  # Increase volume of the audio by 10 decibels\n  louder = song+10\n  louder.export(path+\".wav\")","metadata":{"id":"oATxjbyrs4e8","execution":{"iopub.status.busy":"2024-08-04T06:06:57.84078Z","iopub.execute_input":"2024-08-04T06:06:57.841135Z","iopub.status.idle":"2024-08-04T06:06:57.845907Z","shell.execute_reply.started":"2024-08-04T06:06:57.841108Z","shell.execute_reply":"2024-08-04T06:06:57.844935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Playing the Noisy audio sample1\nfrom IPython.display import Audio\nAudio('/kaggle/input/letsdoit/MIXED/content/MIXED/combined_0004.wav')","metadata":{"id":"_-zntNVTJjTq","outputId":"166b1957-d688-494f-ad3b-312044ef0e32","execution":{"iopub.status.busy":"2024-08-04T06:29:29.492312Z","iopub.execute_input":"2024-08-04T06:29:29.492745Z","iopub.status.idle":"2024-08-04T06:29:29.538036Z","shell.execute_reply.started":"2024-08-04T06:29:29.492715Z","shell.execute_reply":"2024-08-04T06:29:29.537136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction on audio sample 0004\n","metadata":{"id":"xAxmIQv8rV1w"}},{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git\n!sudo apt update && sudo apt install ffmpeg","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:32:38.588128Z","iopub.execute_input":"2024-08-04T08:32:38.588549Z","iopub.status.idle":"2024-08-04T08:33:24.686653Z","shell.execute_reply.started":"2024-08-04T08:32:38.588513Z","shell.execute_reply":"2024-08-04T08:33:24.68522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!whisper '/kaggle/input/letsdoit/ORIGINAL/content/ORIGINAL/original_0004.wav' --task translate","metadata":{"execution":{"iopub.status.busy":"2024-08-04T06:30:24.576947Z","iopub.execute_input":"2024-08-04T06:30:24.57772Z","iopub.status.idle":"2024-08-04T06:30:42.799726Z","shell.execute_reply.started":"2024-08-04T06:30:24.577688Z","shell.execute_reply":"2024-08-04T06:30:42.79848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!whisper '/kaggle/input/letsdoit/MIXED/content/MIXED/combined_0004.wav' --task translate","metadata":{"execution":{"iopub.status.busy":"2024-08-04T06:31:47.065602Z","iopub.execute_input":"2024-08-04T06:31:47.066569Z","iopub.status.idle":"2024-08-04T06:31:57.387759Z","shell.execute_reply.started":"2024-08-04T06:31:47.066533Z","shell.execute_reply":"2024-08-04T06:31:57.38664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction('/kaggle/input', '/kaggle/working', '/kaggle/input/weights', ['combined_0004.wav'],\n        'predicted_0004.wav')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:26:29.977925Z","iopub.execute_input":"2024-08-04T08:26:29.978321Z","iopub.status.idle":"2024-08-04T08:26:29.983575Z","shell.execute_reply.started":"2024-08-04T08:26:29.978289Z","shell.execute_reply":"2024-08-04T08:26:29.982631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!whisper '/kaggle/working/predicted_0004.wav' --task translate","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:33:52.752645Z","iopub.execute_input":"2024-08-04T08:33:52.753499Z","iopub.status.idle":"2024-08-04T08:34:14.574191Z","shell.execute_reply.started":"2024-08-04T08:33:52.753458Z","shell.execute_reply":"2024-08-04T08:34:14.572815Z"},"trusted":true},"execution_count":null,"outputs":[]}]}